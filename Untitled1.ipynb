{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "mount_file_id": "1oJLp7VGL6_hngDxRazTZkaRdzq0f7F5U",
      "authorship_tag": "ABX9TyNvTc92IM5qyHyK07C1OVRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akolol40/TestTask/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UN2ReiGlKNF",
        "outputId": "b667e52b-923b-4837-ac37-b3f3496fde76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 10 classes.\n",
            "Found 81 images belonging to 10 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 31, 31, 32)        896       \n",
            "                                                                 \n",
            " average_pooling2d_6 (Averag  (None, 15, 15, 32)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " average_pooling2d_7 (Averag  (None, 7, 7, 64)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " average_pooling2d_8 (Averag  (None, 3, 3, 64)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                36928     \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,898\n",
            "Trainable params: 93,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            " 19/100 [====>.........................] - ETA: 15:17 - loss: 2.3360 - accuracy: 0.0855"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import tensorflow\n",
        "import librosa.display\n",
        "import IPython.display\n",
        "import random\n",
        "import warnings\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import csv\n",
        "# Предварительная обработка sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Keras\n",
        "import keras\n",
        "from keras import optimizers\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras import layers\n",
        "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, \\\n",
        "    GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    # изменение масштаба всех значений пикселей с 0 до 255, после этого шага они будут находится в диапазоне (0,1)\n",
        "    shear_range=0.2,  # применение случайных преобразований\n",
        "    zoom_range=0.2,  # увеличение масштаба\n",
        "    horizontal_flip=True)  # горизонтальный поворот\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    './drive/MyDrive/data/train',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    './drive/MyDrive/data/val',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "model = Sequential()\n",
        "input_shape = (64, 64, 3)\n",
        "# первый скрытый слой\n",
        "model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "# второй скрытый слой\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(AveragePooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "# третий скрытый слой\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(AveragePooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "# слой выравнивания\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(rate=0.5))\n",
        "# полносвязный слой\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "# выходной слой\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 8\n",
        "learning_rate = 0.01\n",
        "decay_rate = learning_rate / epochs\n",
        "momentum = 0.9\n",
        "sgd = tensorflow.keras.optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "\n",
        "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "        training_set,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=50,\n",
        "        validation_data=test_set,\n",
        "        validation_steps=200)\n",
        "\n",
        "test_set.reset()\n",
        "\n",
        "pred = model.predict_generator(test_set, steps=50, verbose=1)\n",
        "\n",
        "predicted_class_indices = np.argmax(pred, axis=1)\n",
        "labels = (training_set.class_indices)\n",
        "labels = dict((v, k) for k, v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "predictions = predictions[:200]\n",
        "filenames = test_set.filenames\n",
        "print(len(filenames), len(predictions))\n",
        "results = pd.DataFrame({\"Filename\": filenames,\n",
        "                        \"Predictions\": predictions})\n",
        "results.to_csv(\"prediction_results.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "cftNuvxUlLmR"
      }
    }
  ]
}